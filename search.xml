<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ConcurrentHashMap实现原理及源码分析]]></title>
    <url>%2F2018%2F10%2F12%2Fconcurrenthashmap%2F</url>
    <content type="text"><![CDATA[Map 这样的 Key Value 在软件开发中是非常经典的结构，常用于在内存中存放数据。本篇主要想讨论 ConcurrentHashMap 这样一个并发容器 HashMap众所周知 HashMap 底层是基于 数组 + 链表 组成的，不过在 jdk1.7 和 1.8 中具体实现稍有不同。 简单总结下 HashMap：无论是 1.7 还是 1.8 其实都能看出 JDK 没有对它做任何的同步操作，所以并发会出问题，甚至 1.7 中出现死循环导致系统不可用（1.8 已经修复死循环问题）。 想要避免Hashmap的线程安全问题有很多办法，比如改用Hashtable或者Collections.synchronizedMap。但是，这两者有着共同的问题：性能。无论读操作还是写操作，它们都会给整个集合加锁，导致同一时间的其他操作为止阻塞 ConcurrentHashMapConcurrentHashMap 同样也分为 1.7 、1.8 版，两者在实现上略有不同。 Base 1.7先来看看 1.7 的实现，下面是他的结构图： 如图所示，是由 Segment 数组、HashEntry 组成，和 HashMap 一样，仍然是数组加链表。 它的核心成员变量： 123456/** * Segment 数组，存放数据时首先需要定位到具体的 Segment 中。 */final Segment&lt;K,V&gt;[] segments;transient Set&lt;K&gt; keySet;transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; Segment 是 ConcurrentHashMap 的一个内部类，主要的组成如下： 1234567891011static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; private static final long serialVersionUID = 2249069246763182397L; // 和 HashMap 中的 HashEntry 作用一样，真正存放数据的桶 transient volatile HashEntry&lt;K,V&gt;[] table; transient int count; transient int modCount; transient int threshold; final float loadFactor; &#125; 看看其中 HashEntry 的组成： 和 HashMap 非常类似，唯一的区别就是其中的核心数据如 value ，以及链表都是 volatile 修饰的，保证了获取时的可见性。 原理上来说：ConcurrentHashMap 采用了分段锁技术，其中 Segment 继承于 ReentrantLock。不会像 HashTable 那样不管是 put 还是 get 操作都需要做同步处理，理论上 ConcurrentHashMap 支持 CurrencyLevel (Segment 数组数量)的线程并发。每当一个线程占用锁访问一个 Segment 时，不会影响到其他的 Segment。 下面也来看看核心的 put get 方法。 put 方法1234567891011public V put(K key, V value) &#123; Segment&lt;K,V&gt; s; if (value == null) throw new NullPointerException(); int hash = hash(key); int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask; if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject // nonvolatile; recheck (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) // in ensureSegment s = ensureSegment(j); return s.put(key, hash, value, false);&#125; 首先是通过 key 定位到 Segment，之后在对应的 Segment 中进行具体的 put。 12345678910111213141516171819202122232425262728293031323334353637383940414243final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; HashEntry&lt;K,V&gt; node = tryLock() ? null : scanAndLockForPut(key, hash, value); V oldValue; try &#123; HashEntry&lt;K,V&gt;[] tab = table; int index = (tab.length - 1) &amp; hash; HashEntry&lt;K,V&gt; first = entryAt(tab, index); for (HashEntry&lt;K,V&gt; e = first;;) &#123; if (e != null) &#123; K k; if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123; oldValue = e.value; if (!onlyIfAbsent) &#123; e.value = value; ++modCount; &#125; break; &#125; e = e.next; &#125; else &#123; if (node != null) node.setNext(first); else node = new HashEntry&lt;K,V&gt;(hash, key, value, first); int c = count + 1; if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY) rehash(node); else setEntryAt(tab, index, node); ++modCount; count = c; oldValue = null; break; &#125; &#125; &#125; finally &#123; unlock(); &#125; return oldValue;&#125; 虽然 HashEntry 中的 value 是用 volatile 关键词修饰的，但是并不能保证并发的原子性，所以 put 操作时仍然需要加锁处理。 首先第一步的时候会尝试获取锁，如果获取失败肯定就有其他线程存在竞争，则利用 scanAndLockForPut() 自旋获取锁。 尝试自旋获取锁。 如果重试的次数达到了 MAX_SCAN_RETRIES 则改为阻塞锁获取，保证能获取成功。 再结合图看看 put 的流程。 将当前 Segment 中的 table 通过 key 的 hashcode 定位到 HashEntry。 遍历该 HashEntry，如果不为空则判断传入的 key 和当前遍历的 key 是否相等，相等则覆盖旧的 value。 不为空则需要新建一个 HashEntry 并加入到 Segment 中，同时会先判断是否需要扩容。 最后会解除在 1 中所获取当前 Segment 的锁。 get 方法1234567891011121314151617public V get(Object key) &#123; Segment&lt;K,V&gt; s; // manually integrate access methods to reduce overhead HashEntry&lt;K,V&gt;[] tab; int h = hash(key); long u = (((h &gt;&gt;&gt; segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE; if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u)) != null &amp;&amp; (tab = s.table) != null) &#123; for (HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE); e != null; e = e.next) &#123; K k; if ((k = e.key) == key || (e.hash == h &amp;&amp; key.equals(k))) return e.value; &#125; &#125; return null;&#125; 只需要将 Key 通过 Hash 之后定位到具体的 Segment ，再通过一次 Hash 定位到具体的元素上。 由于 HashEntry 中的 value 属性是用 volatile 关键词修饰的，保证了内存可见性，所以每次获取时都是最新值。 ConcurrentHashMap 的 get 方法是非常高效的，因为整个过程都不需要加锁。 Base 1.81.7 已经解决了并发问题，并且能支持 N 个 Segment 这么多次数的并发，但依然存在 HashMap 在 1.7 版本中的问题。 那就是查询遍历链表效率太低。 因此 1.8 做了一些数据结构上的调整。 首先来看下底层的组成结构： 看起来是不是和 1.8 HashMap 结构类似？ 其中抛弃了原有的 Segment 分段锁，而采用了 CAS + synchronized 来保证并发安全性。 也将 1.7 中存放数据的 HashEntry 改为 Node，但作用都是相同的。 其中的 val next 都用了 volatile 修饰，保证了可见性。 put 方法重点来看看 put 函数： 根据 key 计算出 hashcode 。 判断是否需要进行初始化。 f 即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。 如果当前位置的 hashcode == MOVED == -1,则需要进行扩容。 如果都不满足，则利用 synchronized 锁写入数据。 如果数量大于 TREEIFY_THRESHOLD 则要转换为红黑树。 get 方法 根据计算出来的 hashcode 寻址，如果就在桶上那么直接返回值。 如果是红黑树那就按照树的方式获取值。 就不满足那就按照链表的方式遍历获取值。 1.8 在 1.7 的数据结构上做了大的改动，采用红黑树之后可以保证查询效率（O(logn)），甚至取消了 ReentrantLock 改为了 synchronized，这样可以看出在新版的 JDK 中对 synchronized 优化是很到位的。 引申HashMap负载因子为什么是0.75为什么加载因子要默认是0.75？从hashmap源码注释里找到了这一段 12345678910111213141516* parameter of about 0.5 on average for the default resizing* threshold of 0.75, although with a large variance because of* resizing granularity. Ignoring variance, the expected* occurrences of list size k are (exp(-0.5) * pow(0.5, k) /* factorial(k)). The first values are:** 0: 0.60653066* 1: 0.30326533* 2: 0.07581633* 3: 0.01263606* 4: 0.00157952* 5: 0.00015795* 6: 0.00001316* 7: 0.00000094* 8: 0.00000006* more: less than 1 in ten million 简单翻译一下就是在理想情况下,使用随机哈希码,节点出现的频率在hash桶中遵循泊松分布，同时给出了桶中元素个数和概率的对照表。 从上面的表中可以看到当桶中元素到达8个的时候，概率已经变得非常小，也就是说用0.75作为加载因子，每个碰撞位置的链表长度超过８个是几乎不可能的。 好了，再深挖就要挖到统计学那边去了，就此打住，重申一下使用hash容器请尽量指定初始容量，且是2的幂次方。 HashMap为什么长度建议是2的幂次方HashMap里面的数组size必须是2的次幂原因： 1.让元素分布均匀 我们希望元素存放的更均匀，最理想的效果是Entry数组中每个位置都只有一个元素，这样，查询的时候效率最高，不需要遍历单链表，也不需要通过equals去比较Key，而且空间利用率最大。那么如何计算才会分布最均匀呢？我们首先想到的就是%运算，哈希值%容量=bucketIndex，我们来看源码 123static int indexFor(int h,int length)&#123; return h &amp; (length - 1);&#125; h是通过k的hashCode最终计算出来的哈希值，并不是hashCode本身，而是hashCode之上又经过一层运算的hash值，length是目前容量。当容量是2^n时，h &amp; (length -1) == h % length。 2.节约空间 如果length不是2的次幂，比如length为15，则length-1为14，对应的二进制为1110，在于h与操作，最后一位都为0，而0001，0011，0101，1001，1011，0111，1101这几个位置永远都不能存放元素了，空间浪费相当大，更糟的是这种情况中，数组可以使用的位置比数组长度小了很多，这意味着进一步增加了碰撞的几率，减慢了查询的效率！这样就会造成空间的浪费 ConcurrentHashMap的扩容过程回顾一下 transfer 的相关代码： 1234567891011121314151617181920212223242526int runBit = fh &amp; n;Node&lt;K,V&gt; lastRun = f; for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; // 取于桶中每个节点的 hash 值 int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125;&#125;if (runBit == 0) &#123;// 如果最后更新的 runBit 是 0 ，设置低位节点 ln = lastRun; hn = null;&#125;else &#123; hn = lastRun; // 如果最后更新的 runBit 是 1， 设置高位节点 ln = null;&#125;for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; // 如果与运算结果是 0，那么就还在低位 if ((ph &amp; n) == 0) // 如果是0 ，那么创建低位节点 ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else // 1 则创建高位 hn = new Node&lt;K,V&gt;(ph, pk, pv, hn);&#125; 关键看上面注释的代码，如果 runBit 是 0，那么就设置在低位节点，反之，如果是 1，设置在高位。为什么这么设计呢？这要从 ConcurrentHashMap 的取于下标算法开始说起。我们知道，在 putVal 方法中，会通过取于对象的 hash 值获取下标。具体代码如下： 1else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; 也就是 (n - 1) &amp; hash)，这个 n 就是 length。这个其实相当于 hash % n（n 必须是2的指数）。但是比 % 更高效。 复习一下与运算：第一个操作数的的第n位于第二个操作数的第n位如果都是1，那么结果的第n为也为1，否则为0. 然后开始推导：123456789101112131415161718192021222324(n - 1) &amp; hash),取于算法。假设，我们的 table 长度是 16，也就是 10000，减一就是 01111. 取于下面这个数。这个数特别之处在于,他的右起第 5 位是 0。如果是 10000 &amp; 这个数，结果是 0.000000001111 000000010000 010101001001 // 结果 9 010101001001 // &amp;运算结果： 0当我们扩容后，16 变成 32，也就是 10000. 再看看 (n - 1) &amp; hash) 的结果：000000011111 010101001001 // 结果还是 9从这里可以看出，如果 &amp; 运算是 0 ，那么即使扩容，下标也是不变的。再看看另一种情况，换一个 hash 数字，右起第五位是 1 ： 000000001111 000000010000010101010001 // 结果 1 010101010001 // &amp;运算结果： 1这里的 &amp; 与运算后，结果是 1，和上面的不同。同时， (n - 1) &amp; hash) 的结果也是 1.当扩容后，结果是什么样子呢？000000011111010101010001 // 结果变化：10001 == 17可以看到，(n - 1) &amp; hash) 的结果是 17，17 - 1，刚好是 16，而这个 16 的原因是我们的二进制进了一位。 现在明白了吧？0 在低位，1 在高位不是随便设计的。这里让我想到了一致性 hash 算法：当桶的数量变化了，那么 hash 的位置也会变化。这里的设计是为了防止下次取值的时候，hash 不到正确的位置。实际上，JDK 1.8 的 HashMap 也是这么实现的重新散列。 ConcurrentHashMap(JDK1.8)为什么要放弃Segment为什么是synchronized，而不是可重入锁 1.减少内存开销 假设使用可重入锁来获得同步支持，那么每个节点都需要通过继承AQS来获得同步支持。但并不是每个节点都需要获得同步支持的，只有链表的头节点（红黑树的根节点）需要同步，这无疑带来了巨大内存浪费。 2.获得JVM的支持 可重入锁毕竟是API这个级别的，后续的性能优化空间很小。 synchronized则是JVM直接支持的，JVM能够在运行时作出相应的优化措施：锁粗化、锁消除、锁自旋等等。这就使得synchronized能够随着JDK版本的升级而不改动代码的前提下获得性能上的提升。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>hashmap</tag>
        <tag>ConcurrentHashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建Git服务器]]></title>
    <url>%2F2018%2F09%2F25%2Fgit%2F</url>
    <content type="text"><![CDATA[搭建Git服务器GitHub就是一个免费托管开源代码的远程仓库。但是对于某些视源代码如生命的商业公司来说，既不想公开源代码，又舍不得给GitHub交保护费，那就只能自己搭建一台Git服务器作为私有仓库使用。 搭建Git服务器需要准备一台运行Linux的机器，强烈推荐用Ubuntu或Debian，这样，通过几条简单的apt命令就可以完成安装。假设你已经有sudo权限的用户账号，下面，正式开始安装。 第一步，安装git：1$ sudo apt-get install git 第二步，创建一个git用户，用来运行git服务：1$ sudo adduser git 第三步，创建证书登录：收集所有需要登录的用户的公钥，就是他们自己的id_rsa.pub文件，把所有公钥导入到/home/git/.ssh/authorized_keys文件里，一行一个。 客户端 ssh-keygen -t rsa ssh-copy-id -i ~/.ssh/id_rsa.pub &lt;user&gt;@&lt;romte_ip&gt; 服务器 cat ~/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys 在服务器上更改权限(必须) chmod 755 ~ chmod 700 ~/.ssh chmod 644 ~/.ssh/authorized_keys 第四步，初始化Git仓库：先选定一个目录作为Git仓库，假定是/srv/sample.git，在/srv目录下输入命令： 1$ sudo git init --bare sample.git Git就会创建一个裸仓库，裸仓库没有工作区，因为服务器上的Git仓库纯粹是为了共享，所以不让用户直接登录到服务器上去改工作区，并且服务器上的Git仓库通常都以.git结尾。然后，把owner改为git： 1$ sudo chown -R git:git sample.git 第五步，禁用shell登录：出于安全考虑，第二步创建的git用户不允许登录shell，这可以通过编辑/etc/passwd文件完成。找到类似下面的一行： 1git:x:1001:1001:,,,:/home/git:/bin/bash 改为： 1git:x:1001:1001:,,,:/home/git:/usr/bin/git-shell 这样，git用户可以正常通过ssh使用git，但无法登录shell，因为我们为git用户指定的git-shell每次一登录就自动退出。 第六步，克隆远程仓库：现在，可以通过git clone命令克隆远程仓库了，在各自的电脑上运行： 123$ git clone git@server:/srv/sample.gitCloning into &apos;sample&apos;...warning: You appear to have cloned an empty repository. 剩下的推送就简单了。 管理公钥如果团队很小，把每个人的公钥收集起来放到服务器的/home/git/.ssh/authorized_keys文件里就是可行的。如果团队有几百号人，就没法这么玩了，这时，可以用Gitosis来管理公钥。 这里我们不介绍怎么玩Gitosis了，几百号人的团队基本都在500强了，相信找个高水平的Linux管理员问题不大。 管理权限有很多不但视源代码如生命，而且视员工为窃贼的公司，会在版本控制系统里设置一套完善的权限控制，每个人是否有读写权限会精确到每个分支甚至每个目录下。因为Git是为Linux源代码托管而开发的，所以Git也继承了开源社区的精神，不支持权限控制。不过，因为Git支持钩子（hook），所以，可以在服务器端编写一系列脚本来控制提交等操作，达到权限控制的目的。Gitolite就是这个工具。 这里我们也不介绍Gitolite了，不要把有限的生命浪费到权限斗争中。 小结 搭建Git服务器非常简单，通常10分钟即可完成； 要方便管理公钥，用Gitosis； 要像SVN那样变态地控制权限，用Gitolite。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用JRebel实现Maven项目热部署（IDEA）]]></title>
    <url>%2F2018%2F09%2F18%2Fjrebel%2F</url>
    <content type="text"><![CDATA[多数Java开发者都抱怨Java开发的效率太低，不像PHP那样的动态编程语言那样，随时修改，随时生效。所以今天我们就给广大Java开发者带来了福音-JRebel 本教程只适合子模块依赖的项目！ 1、安装JRebel 参考：https://blog.csdn.net/xiayiguo/article/details/79328667 2、配置Project Structure 在Artifacts 选项卡中新增项目 Name:选择和war包名一致； Type:Web Application:Archive Output directory:项目target文件夹 3、Run/Debug Configureations 新建Tomcat Server； On ‘Update’ action 选择redeploy； Deployment选项卡中新增选择Artifacts； 在Before launch会话框中确认Bulid和Bulid ‘xx’ artifact是否存在； 4、JRebel 点击侧边栏JRebel选项卡； 勾选需要监控变化的子模块；勾选后会在子模块里生成rebel.xml文件 5、打包1clean package -Pdev -DskipTests -Dmaven.test.skip=true 6、Debug模式运行JRebel 如果存在代码变动，则点击debug console中蓝色redeploy图标]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jrebel</tag>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手写实现一个 HashMap]]></title>
    <url>%2F2018%2F08%2F09%2Fhashmap%2F</url>
    <content type="text"><![CDATA[前言HashMap是Java中常用的集合，而且HashMap的一些思想，对于我们平时解决业务上的一些问题，在思路上有帮助，基于此，本篇博客将分析HashMap底层设计思想，并手写一个迷你版的HashMap！ 对HashMap的思考 第一，如图所示，HashMap有3个要素：hash函数+数组+单链表 第二，对于hash函数而言，需要考虑些什么？ 要快，对于给定的Key，要能够快速计算出在数组中的index。那么什么运算够快呢？显然是位运算！ 要均匀分布，要较少碰撞。说白了，我们希望通过hash函数，让数据均匀分布在数组中，不希望大量数据发生碰撞，导致链表过长。那么怎么办到呢？也是利用位运算，通过对数据的二进制的位进行移动，让hash函数得到的数据散列开来，从而减低了碰撞的概率。 如果发生了碰撞怎么办？上面的图其实已经说明了JDK的HashMap是如何处理hash冲突的，就是通过单链表解决的。那么除了这个方法，还有其他思路么？比如说，如果发生冲突，那么记下这个冲突的位置为index，然后在加上固定步长，即index+step，找到这个位置，看一下是否仍然冲突，如果继续冲突，那么按照这个思路，继续加上固定步长。其实这就是所谓的线性探测来解决Hash冲突的方法！ 通过写一个迷你版的HashMap来深刻理解定义接口1234567891011121314public interface MyMap&lt;K, V&gt; &#123; V put(K k, V v); V get(K k); // hashMap内部的Entry对象 interface Entry&lt;K, V&gt; &#123; public K getKey(); public V getValue(); &#125;&#125; 定义一个接口，对外暴露快速存取的方法。注意MyMap接口内部定义了一个内部接口Entry。 接口实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236public class MyHashMap&lt;K, V&gt; implements MyMap&lt;K, V&gt; &#123; /** * 定义默认数组的大小 2^n */ private static final int DEFAULT_LENGTH = 1 &lt;&lt; 4; /** * 1、哈希表内部的数组的长度，若使用的数组长度超过总长度的0.75 则数组需要进行扩容，扩容将就是将数组长度变为原来的两倍， * 并且将现在的数组内的数据重新hash并均匀的散列分布到新的数组中，所以该操作消耗比较大 * 2、defaultDaaSizeFactory值是经过测试得出，考虑各种因素后的均衡值，值过大会照成扩容的概率下降，消耗少但是存取数据的效率也降低（反之。。。） * 3、0.9或者更大的扩容值，会内置形成大量的链表，存取都需要进行很多的next（）判定查找操作 */ private static final double DEFAULT_LOAD_FACTOR = 0.75; private int defaultLength; private double defaultAddSizeFactory; /** * 已使用数组的长度（put操作或判定并进行++操作） */ private int userSize; /** * 数组之一（即数组中的链表，初始化为null） */ private Entry&lt;K, V&gt;[] table = null; /** * 无参的构造函数,使用默认值(与带参数的构造形成门面模式) */ public MyHashMap() &#123; this(DEFAULT_LENGTH, DEFAULT_LOAD_FACTOR); &#125; /** * 带两个参数的构造函数 * @param defaultInitCapacity 外置的数组默认大小 * @param defaultLoadFactor 外置的扩容值 */ public MyHashMap(int defaultInitCapacity, double defaultLoadFactor) &#123; if (defaultInitCapacity &lt; 0) &#123; throw new IllegalArgumentException(&quot;参数不能为负数:&quot;); &#125; if (defaultLoadFactor &lt;= 0 || Double.isNaN(defaultLoadFactor)) &#123; throw new IllegalArgumentException(&quot;扩容参数必须大于0&quot;); &#125; this.defaultLength = defaultInitCapacity; this.defaultAddSizeFactory = defaultLoadFactor; table = new Entry[this.defaultLength]; &#125; class Entry&lt;K, V&gt; implements MyMap.Entry&lt;K, V&gt; &#123; K k; V v; /** * 指向下一个对象 */ Entry&lt;K, V&gt; next = null; /** * 全参构造 * @param k * @param v * @param next */ public Entry(K k, V v, Entry&lt;K, V&gt; next) &#123; super(); this.k = k; this.v = v; this.next = next; &#125; @Override public K getKey() &#123; return k; &#125; @Override public V getValue() &#123; return v; &#125; &#125; /** * 存数据 * @param k * @param v */ @Override public V put(K k, V v) &#123; V oldValue = null; // 判定是否需要进行扩容 if (userSize &gt; defaultAddSizeFactory * defaultLength) &#123; reSize(defaultLength * 2); &#125; int index = getIndex(k); Entry&lt;K, V&gt; entry = table[index]; // 判定index的数组下标位置中是否已经存放过数据，并且存放数据是后放的数据离的最近 if (entry == null) &#123; table[index] = new Entry(k, v, null); ++userSize; &#125; else if (entry != null) &#123; // 若已经被占用则需要构建一个新的链表 Entry&lt;K, V&gt; e = entry; while (e != null) &#123; if (k == e.getKey() || k.equals(e.getKey())) &#123; oldValue = e.v; e.v = v; return oldValue; &#125; e = e.next; &#125; table[index] = new Entry(k, v, entry); ++userSize; &#125; return oldValue; &#125; /** * 寻找数组位置的下标 * @param k * @return */ private int getIndex(K k) &#123; int index = hash(k) &amp; (defaultLength - 1); return index; &#125; /** * 自己的hash方法(进行大量的位移3后使数据更加散列) * @param k * @return */ private int hash(K k) &#123; int hashCode = k.hashCode(); hashCode = hashCode ^ ((hashCode &gt;&gt;&gt; 20) ^ (hashCode &gt;&gt;&gt; 12)); return hashCode ^ ((hashCode &gt;&gt;&gt; 7) ^ (hashCode &gt;&gt;&gt; 4)); &#125; /** * 数组进行两倍扩容 * 1、创建两倍长度的新数组 * 2、 */ private void reSize(int size) &#123; Entry&lt;K, V&gt;[] newTable = new Entry[size]; defaultLength = size; userSize = 0; // 将原数组中的数组再次进行hash后放入新数组中 againHash(newTable); &#125; /** * 将原数组中的数组再次进行hash后放入新数组中 * @param newTable */ private void againHash(MyHashMap&lt;K, V&gt;.Entry&lt;K, V&gt;[] newTable) &#123; List&lt;Entry&lt;K, V&gt;&gt; entryList = new ArrayList&lt;&gt;(); // 循环遍历数组并将数据加载值entryList中 for (Entry&lt;K, V&gt; entry : table) &#123; if (entry != null) &#123; do &#123; entryList.add(entry); entry = entry.next; &#125; while (entry != null); //foundEntryByRecursive(entry, entryList); &#125; &#125; if (newTable.length &gt; 0) &#123; table = newTable; &#125; for (Entry&lt;K, V&gt; entry : entryList) &#123; put(entry.getKey(), entry.getValue()); &#125; &#125; /** * 查找下一个元素并将数据存入list中(递归) * @param entry * @param entryList */ private void foundEntryByRecursive(MyHashMap&lt;K, V&gt;.Entry&lt;K, V&gt; entry, List&lt;MyHashMap&lt;K, V&gt;.Entry&lt;K, V&gt;&gt; entryList) &#123; if (entry != null &amp;&amp; entry.next != null) &#123; entryList.add(entry); //进行递归查找 foundEntryByRecursive(entry.next, entryList); &#125; else &#123; // 没有nest元素指向 entryList.add(entry); &#125; &#125; /** * 取数据 * @param k */ @Override public V get(K k) &#123; int index = getIndex(k); if (table[index] == null) &#123; throw new NullPointerException(); &#125; return findValueByEqualKey(k, table[index]); &#125; private V findValueByEqualKey(K k, MyHashMap&lt;K, V&gt;.Entry&lt;K, V&gt; entry) &#123; if (k == entry.getKey() || k.equals(entry.getKey())) &#123; return entry.getValue(); &#125; else if (entry.next != null) &#123; return findValueByEqualKey(k, entry.next); &#125; return null; &#125; /** * 获取当时使用了多少个数组 * @return */ public int getUseSize() &#123; return userSize; &#125; public static void main(String[] args) &#123; MyMap&lt;String, String&gt; map = new MyHashMap&lt;&gt;(); for (int i = 0; i &lt; 10000; i++) &#123; map.put(i + &quot;&quot;, &quot;测试&quot; + i); &#125; for (int i = 0; i &lt; 10000; i++) &#123; System.out.println(&quot;第&quot; + i + &quot;个对象值为： &quot; + map.get(i + &quot;&quot;)); &#125; &#125;&#125; reSize()方法中可以看出，对于HashMap而言，如果频繁进行resize/rehash操作，是会影响性能的。resize/rehash的过程，就是数组变大，原来数组中的entry元素一个个的put到新数组的过程，需要注意的是一些状态变量的改变。 OK，一个迷你版的HashMap就写好了]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>hashmap</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式事务最终一致性常用方案]]></title>
    <url>%2F2018%2F07%2F30%2FBASE%2F</url>
    <content type="text"><![CDATA[分布式事务最终一致性常用方案 目前关于事务的几大理论包括：ACID事务特性，CAP分布式理论，以及BASE等。ACID在数据库事务中体现，CAP和BASE则是分布式事务的理论，结合业务系统，例如订单管理，例如仓储管理等，可以借鉴这些理论，从而解决问题。 CAP特性 C（Consistency）一致性是指数据的原子性，在经典的数据库中通过事务来保障，事务完成时，无论成功或回滚，数据都会处于一致的状态，在分布式环境下，一致性是指多个节点数据是否一致； A（Availability）服务一直保持可用的状态，当用户发出一个请求，服务能在一定的时间内返回结果； P（Tolerance of network Partition）在分布式应用中，可能因为一些分布式的原因导致系统无法运转，好的分区容忍性，使应用虽然是一个分布式系统，但是好像一个可以正常运转的整体 BASE特性 BA: Basic Availability 基本业务可用性； S: Soft state 柔性状态； E: Eventual consistency 最终一致性；ACID（Atomicity，Consistency，Isolation，Durability） 最终一致性的常用做法1、单数据库事务 如果应用系统是单一的数据库，那么这个很好保证，利用数据库的事务特性来满足事务的一致性，这时候的一致性是强一致性的。对于java应用系统来讲，很少直接通过事务的start和commit以及rollback来硬编码，大多通过spring的事务模板或者声明式事务来保证； 2、多数据库事务 针对多数据库事务可以根据二阶段提交协议，采用spring 3.0 + Atomikos + JTA进行支持； 3、基于事务型消息队列的最终一致性 借助消息队列，在处理业务逻辑的地方发送消息，业务逻辑处理成功后，提交消息，确保消息是发送成功的，之后消息队列投递来进行处理，如果成功，则结束，如果没有成功，则重试，直到成功，不过仅仅适用业务逻辑中，第一阶段成功，第二阶段必须成功的场景。对应上图中的C流程。 4、基于消息队列+定时补偿机制的最终一致性 前面部分和上面基于事务型消息的队列，不同的是，第二阶段重试的地方，不再是消息中间件自身的重试逻辑了，而是单独的补偿任务机制。其实在大多数的逻辑中，第二阶段失败的概率比较小，所以单独独立补偿任务表出来，可以更加清晰，能够比较明确的直到当前多少任务是失败的。对应上图的E流程。 5、异步回调机制的引入 A应用调用B，在同步调用的返回结果中，B返回成功给到A，一般情况下，这时候就结束了，其实在99.99%的情况是没问题的，但是有时候为了确保100%，记住最起码在系统设计中100%，这时候B系统再回调A一下，告诉A，你调用我的逻辑，确实成功了。其实这个逻辑，非常类似TCP协议中的三次握手。上图中的B流程。 6、类似double check机制的确认机制 在异步回调的过程，A在同步调用B，B返回成功了。这次调用结束了，但是A为了确保，在过一段时间，这个时间可以是几秒，也可以是每天定时处理，再调用B一次，查询一下之前的那次调用是否成功。例如A调用B更新订单状态，这时候成功了，延迟几秒后，A查询B，确认一下状态是否是自己刚刚期望的。上图中的D流程。 分布式事务的缺点1、二阶段提交协议缺点 两阶段提交涉及到多个节点的网络通信,通信时间如果过长,事务的相对时间也就会过长,那么锁定资源的时间也就长了.在高并发的服务中,就会存在严重的性能瓶劲 2、消息队列 在高并发的环境中，我们一般会采用消息队列来避免分布式事务的执行。在使用消息队列时，我们需要做到可靠凭证的保存（分布式事务的消息）,以支付宝和余额宝为例进行说明:支付宝完成扣钱的动作时,记录消息数据,将消息数据和业务数据存在同一个数据库实例中. 12345Begin Transaction update A set amount=amount-1000 where uid=100; insert into message(uid,amount,status) values (1,1000,1)End TransactionCommit; 将支付宝完成扣钱的消息及时发送给余额宝，余额宝完成处理后返回成功消息，支付宝收到消息后，消除消息表中对应的消息记录，即完成本次扣钱操作.总结下来分布式事务转换为多个本地事务，然后依靠重试等方式达到最终一致性。 引申保证分布式系统数据一致性的6种方案]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nodejs 异步I/O和事件驱动]]></title>
    <url>%2F2018%2F06%2F19%2Fnodejs%2F</url>
    <content type="text"><![CDATA[事件驱动、异步、单线程、非阻塞I/O，这是我们听得最多的关于nodejs的介绍，连nodejs官网都是这么写的： Node.js uses an event-driven, non-blocking I/O model that makes it lightweight and efficient, perfect for data-intensive real-time applications that run across distributed devices. 那么nodejs的内部机制到底是怎样的，nodejs的性能瓶颈在哪里？ 问题 线程驱动编程和事件驱动编程之间的区别是什么呢？ nodejs如何靠js和操作系统打交道的? nodejs真的是单线程吗？ nodejs不适合做什么？ 概念探讨上面问题之前，我们先了解下这些概念： 事件驱动：所谓的事件驱动是对一些操作的抽象，比如 鼠标点击抽象成一个事件，收到请求抽象成一个事件，事件是对异步的一种实现。 同步/异步所谓同步，就是在发出一个功能调用时，在没有得到结果之前，该调用就不返回。当一个异步过程调用发出后，调用者不会立刻得到结果。实际处理这个调用的部件是在调用发出后，通过状态、通知来通知调用者，或通过回调函数处理这个调用。 阻塞/非阻塞阻塞调用是指调用结果返回之前，当前线程会被挂起。函数只有在得到结果之后才会返回。非阻塞和阻塞的概念相对应，指在不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回。 注意： 很多人弄混了 同步/异步和 阻塞/非阻塞 的关系，实际上他们并不是对等的，同步不一定会阻塞，只是方法没有返回不代表线程被挂起了，实际上你也可以去做别的工作。异步也并不代表一定是非阻塞，它可以立即返回函数，但是在获取回调的时候采用了不断轮训的方式挂起了线程。 nodejs内部揭秘 这张图就是nodejs的内部构造。最上面一层就是我们常用的nodejs API，都是通过js封装好的，node-bings是指对底层c/c++代码的封装后和js打交道的部分，属于交界区域，这部分大都是原生API源码调用c++的情况，用户是不需要直接使用c++模块的。然后就是底层首先是V8引擎，这个我们非常熟悉，他就是 js 的解析引擎，它的作用就是“翻译”js给计算机看，然而我们今天关注的重点并不是V8.在这里我们也看出来node是v8的关系，v8是js解释引擎，node是js的runtime，相当于浏览器是js的runtime一样，我们接下来解释的东西大都发生在runtime上面。libuv，早期是libev和libeio组成，后来被抽象成libuv，它就是node和操作系统打交道的部分，由它来负责文件系统、网络等等底层工作。也是我们今天重点关注对象。剩下那些这次按住不表。 libuv简介一张图揭示了libuv在node中的作用可以看出，几乎所有和操作系统打交道的部分都离不开 libuv的支持。libuv也是node实现跨操作系统的核心所在。 回答问题线程驱动和事件驱动 线程驱动就是当收到一个请求的时候，将会为该请求开一个新的线程来处理请求。一般存在一个线程池，线程池中有空闲的线程，会从线程池中拿取线程来进行处理，如果线程池中没有空闲的线程，新来的请求将会进入队列排队，直到线程池中空闲线程。 事件驱动就是当进来一个新的请求的时，请求将会被压入队列中，然后通过一个循环来检测队列中的事件状态变化，如果检测到有状态变化的事件，那么就执行该事件对应的处理代码，一般都是回调函数。对于事件驱动编程来说，如果某个时间的回调函数是计算密集型，或者是阻塞I/O,那么这个回调函数将会阻塞后面所有事件回调函数的执行。这一点尤为重要。 js是如何同底层操作系统打交道的？一张简化的图如下(以fs为例)： nodejs既然是单线程，如何实现异步I/O ？js执行线程是单线程，把需要做的I/O交给libuv，自己马上返回做别的事情，然后libuv在指定的时刻回调就行了。其实简化的流程就是酱紫的！细化一点，nodejs会先从js代码通过node-bings调用到C/C++代码，然后通过C/C++代码封装一个叫 请求对象 的东西交给libuv，这个请求对象里面无非就是需要执行的功能+回调之类的东西，给libuv执行以及执行完实现回调。 nodejs真的是单线程吗？从整个系统的角度看，NodeJS不是单线程。但是从你的代码看，NodeJS是单线程。所以，对于NodeJS，有这样的一句话: everything runs in parallel except your code. 1234567891011&apos;use strict&apos;; var fs = require(&apos;fs&apos;); fs.mkdir(&apos;./test&apos;,function(err,data)&#123; if(err) return console.log(&apos;err &apos; + err); console.log(&apos;success &apos; + data); &#125;); while(true)&#123; console.log(&apos;infinity loop&apos;); &#125; test文件夹会被创建吗？ 总结 Node.js 通过 libuv 来处理与操作系统的交互，并且因此具备了异步、非阻塞、事件驱动的能力。 Node.js 实际上是 Javascript 执行线程的单线程，真正的的 I/O 操作，底层 API 调用都是通过多线程执行的。 CPU 密集型的任务是 Node.js 的软肋。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Hexo博客中Disqus在国内不能访问的问题]]></title>
    <url>%2F2018%2F06%2F14%2Fdisqus-proxy%2F</url>
    <content type="text"><![CDATA[思路整体流程是这样的，在前端页面上测试disqus加载是否成功，如果成功则显示disqus的评论框，反之加载独立的评论框，并将请求发送给自己在国外的vps，利用vps做反向代理，接收来自客户端的请求到disqus服务器并再转发给客户端。流程图大概长这样： Demodisqus-proxy 项目地址 准备 一台国外的VPS服务器 基本的命令行相关知识 一点点hexo的使用经验安装在Hexo博客目录执行 1npm install hexo-disqus-proxy --save 前端配置在你的Hexo博客目录中修改_config.yml文件 添加如下配置：（注意缩进和空格） 1234shortname: ciquusername: ciquhost: disqus-proxy.ycwalker.comport: 443 其中： shortname 是你的website的 shortname 名称 比如在你的disqus安装代码中 有这样一句脚本： s.src = ‘https://test-eo9kkdlcze.disqus.com/embed.js&#39;; 那么你的disqus 的shortname 就是 test-eo9kkdlcze username 是你的disqus用户名，即评论时候留下的名字，用来区别disqus-proxy的评论头像显示 host是你启用disqus代理的VPS的域名 port是VPS服务器启用disqus代理的端口，需要与之后配置的后端一致 后端配置disqus-proxy-server 首先，需要获取disqus提供的api-secret。 在 Disqus 申请开启 api 权限。访问register new application 就可以注册一个 application.然后在applications可以看到你的 application 列表。其中 Secret Key 就是我们需要的api-secret,并且需要在后台的Settings =&gt; Community里开启访客评论 使用nodejs 需要Node.js版本7.6以上。 在服务器上clone代码:1https://github.com/ciqulover/disqus-proxy-server 安装依赖1npm install 配置server目录下的config.js1234567891011121314151617181920212223module.exports = &#123; // 服务端端口，需要与disqus-proxy前端设置一致 port: 5509, // 你的diqus secret key api_secret: &apos;your secret key&apos;, // 你的website的 shortname 名称 比如在你的disqus安装代码中 有这样一句脚本： // s.src = &apos;https://test-eo9kkdlcze.disqus.com/embed.js&apos;; // 那么你的disqus 的shortname 就是 test-eo9kkdlcze shortname: &apos;ciqu&apos;, // 服务端socks5代理转发，便于在本地测试，生产环境通常为null // socks5Proxy: &#123; // host: &apos;localhost&apos;, // port: 1086 // &#125;, socks5Proxy: null, // 日志输出位置,输出到文件或控制台 &apos;file&apos; | &apos;console&apos; log: &apos;console&apos;&#125; 启动12npm install pm2 -gpm2 start server.js]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>disqus</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速搭建Hexo博客+webhook自动部署]]></title>
    <url>%2F2018%2F06%2F07%2Fhexo-blog%2F</url>
    <content type="text"><![CDATA[本文档主要用来记录自己借助Hexo搭建博客的一些步骤和命令，方便以后重装；新人也可以通过此篇文章快速搭建自己的个人博客。 下文的环境为:VPS： CentOS6.5本地： win7 http://shankcity.work GitHub 项目地址 搭建博客1、安装 NodeJS 和 NPM1[root@California_VPS ~]# curl --silent --location https://rpm.nodesource.com/setup_8.x | sudo bash - 执行完这个命令之后就可以安装NodeJS 1[root@California_VPS ~]# yum install -y nodejs 这里安装的是8.X版本，如果安装其他版本将setup_8.x中的8改成对应的版本就可以了。安装完成之后执行命令检查安装结果：1234[root@California_VPS ~]# node -vv8.8.1[root@California_VPS ~]# npm -v5.4.2 2、安装 Nginx通过 yum方式安装比较麻烦，还需要安装epel依赖库，下面介绍一种最简单的安装方法1[root@California_VPS ~]# vim /etc/yum.repos.d/nginx.repo 先在 yum.repos.d 文件下新建一个nginx.repo，然后将下面的内容拷贝进去，:wq保存退出12345[nginx]name=nginx repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=0enabled=1 执行下面的命令直接从配置文件安装 nginx1[root@California_VPS ~]# yum install nginx -y 然后启动nginx1[root@c_vps ~]# nginx 然后打开服务器所在的IP测试nginx是否安装完成。 3、安装 Hexo按照官网的文档执行命令1[root@California_VPS ~]# npm install -g hexo-cli 因为需要把之前在 github 的博客备份重新拷贝新的服务器上，所以要配置 ssh 公钥方便 git 操作。 先生成公钥1[root@California_VPS ~]# ssh-keygen -t rsa -b 4096 -C &quot;xxxxx@xxx.com&quot; 一直回车全部使用默认设置就行，这一步会生成ssh公钥，也就是 public key，生成之后可以通过下面的命令查看1ls -al ~/.ssh 如果有 id_rsa id_rsa.pub 证明生成成功，然后通过下面的命令查看 ssh 公钥1cat ~/.ssh/id_rsa.pub 再将这个公钥拷贝到 github 的账户配置中即可。 注意： 为了方便在本地修改博客、实时预览、自动部署，以上（除了Nginx安装）所有步骤在本地机器上也需要重新操作一遍，以后在本地直接修改之后推送github，配合下文的webhook，服务器会自动更新 4、配置博客新安装：参照 Hexo官方教程重装：从 github 上把之前的博客 clone 下来，放到 root 目录下：1git clone git@github.com:gaoshilei/hexo-blog.git 进入博客目录，一次执行下面的命令12[root@c_vps hexo-blog]# npm install hexo[root@c_vps hexo-blog]# npm install 然后配置 nginx，让 80 端口指向博客静态页面首页，在 nginx 配置文件目中新建一个hexo.conf文件1[root@California_VPS ~]# vim /etc/nginx/conf.d/hexo.conf 写入相应的配置12345678server &#123; listen 80; server_name shankcity.work; location / &#123; root /root/hexo_blog/public; index index.html; &#125;&#125; 重启 nginx 使服务生效1[root@California_VPS ~]# nginx -s reload 此时去访问博客得到的是一个 404 或者 403 报错，因为 nginx 是以 nginx 用户运行的，他没有博客目录的读写权限，有两个方法可以解决： 给博客目录赋权，让 nginx 用户拥有读写权限让 nginx 以 root 用户运行我采用第二种方式，修改 nginx 的配置文件1[root@California_VPS ~]# vim /etc/nginx/nginx.conf 将 user nginx; 改成 user root; 即可。然后重启 nginx。 再去访问发现报错没了，但是页面是一片空白，找了半天原因，之前用到的主题并没有上传到 github 上，将主题拷贝到 themes 文件夹下，然后部署 hexo 就可以正常访问了。 hexo 常用的命令生成静态文件并部署网站: 安装 hexo 服务（本地可以通过这个服务实现预览，不需要安装nginx）1# npm install hexo-server --save 启动 hexo 服务，默认端口为 40001# hexo server 用指定端口(port)启动启动 hexo 服务1# hexo server -p port 生成静态文件1# hexo g 清除缓存文件 (db.json) 和已生成的静态文件 (public)1# hexo clean 生成站点map12# npm install hexo-generator-sitemap --save# npm install hexo-generator-baidu-sitemap --save 配置 webhooks 自动更新博客每次在本地更新了博客，push 到 github 上，还要去 VPS 再 git pull 一下，确实很麻烦，配置好 webhooks 就可以在 github 有 push 操作时自动更新并部署博客。 webhooks 在 github 对应仓库直接设置就行，重点是服务器的接收和相应的操作。有 Python、PHP、NodeJS 多种方式可以接收 webhooks , 由于 hexo 是基于 NodeJS 的，所以这里用 NodeJS 来接收 github 的 push 事件。 安装依赖库 github-webhook-handler：1[root@California_VPS ~]# npm install -g github-webhook-handler 安装完成之后配置 webhooks.js1[root@California_VPS hexo-blog]# vim webhooks.js 然后将下面代码的拷贝进去123456789101112131415161718192021222324252627282930var http = require(&apos;http&apos;)var createHandler = require(&apos;github-webhook-handler&apos;)var handler = createHandler(&#123; path: &apos;/webhooks_push&apos;, secret: &apos;leonlei1226&apos; &#125;)// 上面的 secret 保持和 GitHub 后台设置的一致function run_cmd(cmd, args, callback) &#123; var spawn = require(&apos;child_process&apos;).spawn; var child = spawn(cmd, args); var resp = &quot;&quot;; child.stdout.on(&apos;data&apos;, function(buffer) &#123; resp += buffer.toString(); &#125;); child.stdout.on(&apos;end&apos;, function() &#123; callback (resp) &#125;);&#125;handler.on(&apos;error&apos;, function (err) &#123; console.error(&apos;Error:&apos;, err.message)&#125;)handler.on(&apos;push&apos;, function (event) &#123; console.log(&apos;Received a push event for %s to %s&apos;, event.payload.repository.name, event.payload.ref); run_cmd(&apos;sh&apos;, [&apos;./deploy.sh&apos;], function(text)&#123; console.log(text) &#125;);&#125;)try &#123; http.createServer(function (req, res) &#123; handler(req, res, function (err) &#123; res.statusCode = 404 res.end(&apos;no such location&apos;) &#125;) &#125;).listen(6666)&#125;catch(err)&#123; console.error(&apos;Error:&apos;, err.message)&#125; 其中 secret 要和 github 仓库中 webhooks 设置的一致，6666 是监听端口可以随便改，不要冲突就行，./deploy.sh 是接收到 push 事件时需要执行的shell脚本，与 webhooks.js 都存放在博客目录下；path: ‘/webhooks_push 是 github 通知服务器的地址，完整的地址是这样的http://www.gaoshilei.com:6666/webhooks_push 用 https 会报错，github 设置页面会 deliver error，所以把地址改成了 http 配置./deploy.sh1[root@California_VPS hexo-blog]# vim deploy.sh 将下面代码拷贝进去1234cd /root/hexo-blog/git reset --hardgit pull origin master hexo generate 然后运行1[root@California_VPS hexo-blog]# node webhooks.js 就可以实现本地更新 push 到 github ，服务器会自动更新部署博客。最后要将进程加入守护，通过 pm2 来实现1[root@California_VPS ~]# npm install pm2 --global 然后通过 pm2 启动 webhooks.js123456789[root@California_VPS hexo-blog]# pm2 start /root/hexo-blog/webhooks.js [PM2] Starting /root/hexo-blog/webhooks.js in fork_mode (1 instance)[PM2] Done.┌──────────┬────┬──────┬───────┬────────┬─────────┬────────┬─────┬───────────┬──────┬──────────┐│ App name │ id │ mode │ pid │ status │ restart │ uptime │ cpu │ mem │ user │ watching │├──────────┼────┼──────┼───────┼────────┼─────────┼────────┼─────┼───────────┼──────┼──────────┤│ webhooks │ 0 │ fork │ 10010 │ online │ 0 │ 0s │ 14% │ 24.2 MB │ root │ disabled │└──────────┴────┴──────┴───────┴────────┴─────────┴────────┴─────┴───────────┴──────┴──────────┘ Use `pm2 show &lt;id|name&gt;` to get more details about an app 如果服务器重启，我们还要手动开启webhooks服务，所以我们将上面的命令加入开机启动就可以了，将命令加入/etc/rc.d/rc.local中，即可实现开机自启先将命令写到脚本/root/webhooks_auto.sh中：1/sbin/runuser -l root -c &quot;/usr/bin/pm2 start /root/hexo-blog/webhooks.js&quot; 然后在/etc/rc.d/rc.local中添加刚才的脚本：1/root/webhooks_auto.sh 2&gt;&amp;1 &gt; /dev/null &amp; 重启VPS，然后用命令pm2 show webhooks查看 webhooks 是否已经启动。 全站 HTTPS使用 Let’s Encrypt 的免费证书，不过每三个月要续签一次。安装可以通过 Certbot 的傻瓜式操作12[root@California_VPS www]# wget https://dl.eff.org/certbot-auto[root@California_VPS www]# chmod a+x certbot-auto 下载脚本，然后赋权1[root@California_VPS www]# sudo ./certbot-auto --nginx 执行脚本，获取证书，Certbot 会自动帮我们配置 nginx 的一些配置。走到最后可能遇到这种情况 Cannot find a VirtualHost matching domain www.gaoshilei.com. In order for Certbot to correctly perform the challenge please add a corresponding server_name directive to your nginx configuration: https://nginx.org/en/docs/http/server_names.html 之前在配置 nginx.conf 文件的时候忘记加域名了，把 server_name 补全就行了，然后重新执行一次脚本。你还可能遇到这样的问题12Creating virtual environment...[root@California_VPS www]# ./certbot-auto: line 864: virtualenv: command not found 缺少virtualenv环境，依次执行下面的命令下面进行安装：12[root@California_VPS www]# curl https://bootstrap.pypa.io/get-pip.py | python -[root@California_VPS www]# pip install virtualenv 然后执行上面的命令sudo ./certbot-auto –nginx继续安装证书，中间需要我们输入邮箱，域名等等，按照步骤操作就可以，最后顺利申请了证书，而且 Certbot 都帮我配置好了，nice！不过这个证书有效期只有三个月，所以需要续签，可以手动续签，证书快过期的时候执行1# sudo /root/www/certbot-auto renew 或者将上面的命令加入 crontab 定时任务12345[root@California_VPS etc]# ps -ef | grep cronroot 1164 1 0 Oct30 ? 00:00:00 crondroot 8507 8222 0 07:31 pts/0 00:00:00 grep cron [root@California_VPS etc]# service crond statuscrond (pid 1164) is running... 先检查一下有没有安装 crontab，并且查看 crontab 的运行状态。最后配置1[root@California_VPS etc]# crontab -e 添加下面这条命令到配置文件中10 0 * * 0 /root/www/certbot-auto renew 这条命令的意思是每周日的0点0分执行/root/www/certbot-auto renew这条命令。执行下面这条命令查看定时任务列表中是否有刚才添加的任务12[root@California_VPS etc]# crontab -l 0 0 * * 0 /root/www/certbot-auto renew 主题GitHub 项目地址 克隆到theme目录下1git clone --branch v5.1.2 https://github.com/iissnan/hexo-theme-next themes/next 配置 Configuration123456789101112131415161718192021# Menu configuration.menu: home: / archives: /archives# Faviconfavicon: /favicon.ico# Avatar (put the image into next/source/images/)# can be any image format supported by web browsers (JPEG,PNG,GIF,SVG,..)avatar: /default_avatar.png# Code highlight theme# available: normal | night | night eighties | night blue | night brighthighlight_theme: normal# Fancybox for image galleryfancybox: true# Specify the date when the site was setupsince: 2018 大功告成！]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[教你用 Python 来玩微信跳一跳]]></title>
    <url>%2F2018%2F06%2F07%2Fwechat-jump%2F</url>
    <content type="text"><![CDATA[https://wangshub.github.io GitHub 项目地址 游戏模式 2017 年 12 月 28 日下午，微信发布了 6.6.1 版本，加入了「小游戏」功能，并提供了官方 DEMO「跳一跳」。 这是一个 2.5D 插画风格的益智游戏，玩家可以通过按压屏幕时间的长短来控制这个「小人」跳跃的距离。可能刚开始上手的时候，因为时间距离之间的关系把握不恰当，只能跳出几个就掉到了台子下面。 玩法类似于《Flappy Bird》 如果能精确测量出起始和目标点之间测距离，就可以估计按压的时间来精确跳跃？所以花 2 个小时写了一个 Python 脚本进行验证 希望不要把分数刷太高，容易没朋友的。。。 操作规范 考虑到生产环境的规范性，实验与项目之间不受干扰，请尽量用新的虚拟环境来完成实验 MacOS/Win,请使用如下操作开辟新的虚拟环境（不强调表示MacOS/Win相同操作） 下载Anaconda. MacOS:默认安装/Win:注意安装时候勾选配置路径或者之后手动配置，直至cmd后conda关键字有效 查看所有的虚拟环境conda info --envs 使用命令：conda create -n wechat_env python=3，创建名为wechat_env的虚拟环境，且配置python版本为python3 激活虚拟环境：MacOS: source activate wechat_env/Win：activate wechat_env 安装所需要的包，比如matplotlib等，建议使用conda install package_name来避免虚拟环境包的路径问题 接下来的操作非必须，仅当实验完成后可操作，试验阶段全程在虚拟环境中操作，进入虚拟环境会有前置符号表示如： 12(wechat_env) ~/Desktop/wechat_jump_game-master&gt; 退出虚拟环境：MacOS: source deactivate wechat_env / Win: deactivate wecha_env 删除虚拟环境： conda remove -n wechat_env --all 工具介绍 Python 手机或模拟器 ADB 驱动，可以到这里下载 相关依赖 如果你是iOS + MacOS，请参考下面的配置： 使用真机调试 WDA，参考 iOS 真机如何安装WebDriverAgent · TesterHome 安装openatx/facebook-wda Python 3 如果你是 Android + MacOS，请参考下面的配置： Python 3 使用brew进行安装 brew cask install android-platform-tools 安装完后插入安卓设备且安卓已打开usb调试模式（部分新机型可能需要再另外勾上 允许模拟点击 权限），终端输入 adb devices ,显示如下表明设备已连接 1234List of devices attached6934dc33 device 如果你是 Android + Windows，请参考下面的配置： Python 3 安装 ADB 后，请在 环境变量 里将 adb 的安装路径保存到 PATH 变量里，确保 adb 命令可以被识别到。 同 Android + MacOS 测试连接 关于Win+Android的adb调试添加路径等问题，可以尝试使用Tools文件夹中adb文件夹进行调试，详见adb中readme文件 依赖安装12pip install -r requirements.txt 原理说明 将手机点击到《跳一跳》小程序界面； 用 ADB 工具获取当前手机截图，并用 ADB 将截图 pull 上来 1234adb shell screencap -p /sdcard/autojump.pngadb pull /sdcard/autojump.png . 计算按压时间 手动版：用 Matplotlib 显示截图，用鼠标点击起始点和目标位置，计算像素距离； 自动版：靠棋子的颜色来识别棋子，靠底色和方块的色差来识别棋盘； 用 ADB 工具点击屏幕蓄力一跳； 12adb shell input swipe x y x y time(ms) 安卓手机操作步骤 安卓手机打开 USB 调试，设置》开发者选项》USB 调试 电脑与手机 USB 线连接，确保执行adb devices可以找到设备 ID 界面转至微信跳一跳游戏，点击开始游戏 运行python wechat_jump_auto.py，如果手机界面显示 USB 授权，请点击确认 请按照你的手机分辨率从./config/文件夹找到相应的配置，拷贝到 *.py 同级目录./config.json（如果屏幕分辨率能成功探测，会直接调用 config 目录的配置，不需要复制） iOS 手机操作步骤 运行安装好的 WebDriverAgentRunner 将手机点击到《跳一跳》小程序界面 运行脚本。有两种模式可供选择：手动辅助跳 和 自动连续跳 手动辅助跳 命令行运行python3 wechat_jump_iOS_py3.py 依次点击弹出的窗口中的起始位置和目标位置，会自动计算距离后起跳 根据起跳的精准情况更改python3 wechat_jump_iOS_py3.py中的time_coefficient参数，直到获得最佳取值 自动连续跳 拷贝./config/iPhone目录下对应的设备配置文件，重命名并替换到./config.json 命令行运行python3 wechat_jump_auto_iOS.py 会自动计算坐标并连续起跳，根据起跳的精准情况更改./config.json 中的press_coefficient参数，直到获得最佳取值 实验结果 TODO 可以对拉上来的图片进行颜色分割，识别小人和目标中心，这样就不需要手动点击自动弹跳。 事实证明，机器人比人更会玩儿游戏。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F06%2F07%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
